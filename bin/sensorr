#!/usr/bin/env node
const fs = require('fs')
const path = require('path')
const inquirer = require('inquirer')
const chalk = require('chalk')
const ora = require('ora')
const spinners = require('cli-spinners')
const filesize = require('filesize')
const microtime = require('microtime')
const { from, of, merge, interval, zip, throwError, bindNodeCallback, EMPTY } = require('rxjs')
const { map, mapTo, tap, filter, mergeMap, delay, pluck, takeWhile, timeout, catchError } = require('rxjs/operators')
const RxDB = require('rxdb')
const Database = require('../shared/Database')
const Documents = require('../shared/Documents')
const Sensorr = require('../shared/Sensorr')
const TMDB = require('../shared/services/TMDB')
const Plex = require('../shared/services/Plex')
const Transform = require('stream').Transform
const studio = require('@studio/log')
const StringifyTransform = require('@studio/ndjson/stringify')
const uuidv1 = require('uuid/v1')
const uuidv4 = require('uuid/v4')
const config = require('../config/config.json')
const package = require('../package.json')
const { _, ...argv } = require('minimist')(process.argv.slice(2))

require('events').EventEmitter.defaultMaxListeners = 15

const commands = _
const log = console.error

RxDB.plugin(require('pouchdb-adapter-leveldb'))

global.fetch = require('node-fetch')

const parse = (values) => ({
  ...((values.b && { blackhole: values.b }) || (values.blackhole && { blackhole: values.blackhole }) || {}),
  ...((values.f && { filter: values.f }) || (values.filter && { filter: values.filter }) || {}),
  ...((values.s && { sort: values.s }) || (values.sort && { sort: values.sort }) || {}),
  ...((values.d && { descending: values.d }) || (values.descending && { descending: values.descending }) || {}),
})

main(new Sensorr({ ...config, ...parse(argv) }))

async function main(sensorr) {
  await logo()

  if (argv.v || argv.version) {
    await version()
    await exit()
  } else if (argv.h || argv.help || !['record', 'stalk', 'sync'].includes(commands[0])) {
    await help()
    await exit()
  }

  // Waiting feature [Using RxDB to only wrap remote (couch) endpoints #247](https://github.com/pubkey/rxdb/issues/247) to be implemented
  const db = await new Database({ name: `${__dirname}/db/sensorr`, adapter: 'leveldb' }).get()
  const remote = `http://${sensorr.config.auth.username ? `${sensorr.config.auth.username}:${sensorr.config.auth.username}@` : ''}localhost:${parseInt(argv.p || argv.port || 5070)}`
  await synchronize()

  historize()
  const logger = studio('sensorr')

  switch (commands[0]) {
    case 'record':
      await record()
      break
    case 'stalk':
      await stalk()
      break
    case 'sync':
      await sync()
      break
  }

  exit(0)

  function historize() {
    const history = fs.createWriteStream(path.join(__dirname, '..', 'history.log'), { flags: 'a' })

    studio
      .pipe(new Transform({
        readableObjectMode: true,
        writableObjectMode: true,
        transform: ({ data: { context, ...data }, ...entry }, encoding, callback) => {
          db.records.atomicUpsert({
            uuid: uuidv4(),
            ...context,
            data,
            time: microtime.now() / 1000,
            message: entry.msg,
          })

          callback(null, { ...entry, data: { context, ...data } })
        }
      }))
      .pipe(new StringifyTransform())
      .pipe(history)
  }

  async function synchronize (keep = true) {
    return new Promise(resolve => {
      const loading = ora({
        spinner: spinners.earth,
        text: `Syncing database with ${chalk.gray(remote)} ...`,
      })

      const replications = Object.keys(Database.SCHEMAS).map(schema => db[schema].sync({
        remote: `${remote}/db/sensorr-${schema}`,
        waitForLeadership: true,
        options: {
          live: false,
          retry: true,
        },
      }))

      merge(...replications.map(replication => replication.error$)).subscribe(err => {
        loading.stopAndPersist({ symbol: 'ðŸš¨', text: `Error during Database syncing with ${chalk.gray(remote)} : ${err}` })
        exit(1)
      })

      merge(...replications.map(replication => replication.complete$.pipe(
        takeWhile(res => !res || !res.pull.ok),
      )))
      .subscribe(
        () => loading.start(),
        null,
        () => {
          if (keep) {
            Object.keys(Database.SCHEMAS).forEach(schema =>
              db[schema].sync({ remote: `${remote}/db/sensorr-${schema}`, options: { live: true, retry: true } })
            )
          }

          setTimeout(() => {
            loading.stopAndPersist({ symbol: 'ðŸ›ï¸ ', text: `Database synced with ${chalk.gray(remote)} !` })
            resolve()
          }, 500)
        }
      )
    })
  }

  async function exit(code = 0) {
    try { // else, "UnhandledPromiseRejectionWarning: ReferenceError: db is not defined", `typeof db !== 'undefined'` doesn't work
      if (db) {
        await synchronize(false)
      }
    } catch(e) {}

    process.exit(code)
  }

  async function logo() {
    const text = fs.createReadStream(`${__dirname}/logo`)
    text.pipe(process.stderr)
    await new Promise(resolve => text.on('end', resolve))
    log('')
    log('ðŸ¿ ðŸ“¼', ' - ', `${chalk.bold('Movie release radar')} (CouchPotato, Radarr and Watcher3 alternative)`)
    log('')
  }

  async function version() {
    log(`${package.description}`)
    log(`${chalk.bold(package.name)} v${package.version}`)
  }

  async function help() {
    const text = fs.createReadStream(`${__dirname}/help`)
    text.pipe(process.stderr)
    await new Promise(resolve => text.on('end', resolve))
    log('')
  }

  async function record() {
    const session = uuidv1()

    db.sessions.atomicUpsert({ uuid: session, time: microtime.now() / 1000 })

    return await new Promise(resolve =>
      from(db.movies.dump()).pipe(
        pluck('docs'),
        tap(movies => movies.filter(movie => movie.state === 'wished').length ? '' : log('ðŸ‘', 'Up to date, no more wished movies !')),
        map(movies => movies.sort((a, b) => a.time - b.time)),
        mergeMap(movies => from(movies)),
        filter(movie => movie.state === 'wished'),
        mergeMap(movie => {
          const record = uuidv4()
          const context = { session, record }

          return of(movie).pipe(
            mergeMap(movie => look(movie, context)),
            mergeMap(({ movie, release }) => grab(movie, release, context)),
            map(values => ({ ...values, context })),
            catchError(err => {
              log('ðŸš¨', err.toString())
              logger.error(`ðŸš¨ Error during **${movie.title}** (${movie.year}) recording`, { context, movie }, err)
              return EMPTY
            }),
          )
        }, null, 1),
      ).subscribe(
        ({ movie, release, file, context }) => {
          log(
            'ðŸ“¼',
            'Archiving',
            `movie ${chalk.inverse(movie.title)} ${chalk.gray(`(${movie.year})`)}`,
            'with',
            `release ${chalk.inverse(release.title)}`,
            'to',
            chalk.gray(file)
          )

          logger.spawn(
            `ðŸ“¼ Archiving movie **${movie.title}** ${`(${movie.year})`} with release **${release.title}** to _${file}_`,
            { context, release, file },
          )
        },
        (err) => log('ðŸš¨', err),
        () => {
          log('')
          resolve()
        },
      )
    )
  }

  function look(movie, context = {}) {
    log('')
    log('ðŸ¿', `Looking for wished movie ${chalk.inverse(movie.title)} ${chalk.gray(`(${movie.year})`)}`)
    logger.input(`ðŸ¿ Looking for wished movie **${movie.title}** (${movie.year})`, { context, movie })

    const hooks = {
      search: (xznab, title) => {
        log('â˜ ï¸ ', `Looking for ${chalk.bold(title)} on ${chalk.underline(xznab.name)} XZNAB`)
        logger.fetch(`â˜ ï¸ Looking for **${title}** on **${xznab.name}** XZNAB`, { context, xznab, title })
      },
      timeout: (xznab, title) => {
        log('âŒ› ', `Request for ${chalk.bold(title)} on ${chalk.underline(xznab.name)} XZNAB timed out ! Retrying...`)
        logger.fetch(`âŒ› Request for **${title}** on **${xznab.name}** XZNAB timed out ! Retrying...`, { context, xznab, title })
      },
      found: (xznab, title, items) => {
        log('ðŸŽžï¸ ', `Found ${chalk.bold(items.length)} releases`)
        logger.receive(`ðŸŽžï¸ Found **${items.length}** releases` , { context, xznab, title, items })
      },
      release: (xznab, title, release) => {
        log('*', chalk[['green', 'yellow', 'red'][release.warning]](release.title), chalk.gray(release.valid ? `(${release.score})` : release.reason))
        logger.receive(`- ${['**', '**_', '~~'][release.warning]}${release.title}${['**', '_**', '~~'][release.warning]} _${(release.valid ? `(${release.score})` : release.reason)}_`, { context, xznab, title, release })
      },
      sorted: (releases) => {
        if (releases.length)Â {
          log('ðŸš§', `Filtering and ordering ${releases.length} releases`, chalk.gray(`[${sensorr.config.sort}]`), { true: 'ðŸ”»', false: 'ðŸ”º' }[sensorr.config.descending])
          logger.finish(`ðŸš§ Filtering and ordering **${releases.length}** releases [${sensorr.config.sort}] ${{ true: 'ðŸ”»', false: 'ðŸ”º' }[sensorr.config.descending]}`, { context, releases, sort: sensorr.config.sort, descending: sensorr.config.descending })
        } else {
          log('ðŸ“­', `ï¸Sorry, no valid releases found`)
          logger.receive(`ðŸ“­ Sorry, no valid releases found`, { context })
        }
      },
    }

    return sensorr.look(movie, true, hooks).pipe(
      map(releases => releases.sort(sensorr.sort(sensorr.config.sort, sensorr.config.descending))),
      tap(releases => hooks.sorted(releases)),
      filter(releases => releases.length),
      mergeMap(releases => {
        const choices = releases.map(release => [
          (argv.a || argv.auto) ? chalk.green(release.title) : release.title,
          chalk.gray(`(${filesize(release.size)} - ${release.peers} â†“ / ${release.seeders} â†‘)`),
        ].join(' '))

        if (argv.a || argv.auto) {
          choices.forEach(choice => log('*', choice))
          return of(releases[0])
        } else {
          return inquirer.prompt([
            {
              type: 'list',
              name: 'release',
              message: 'Choose release :',
              choices,
            }
          ]).then(answers => releases[choices.indexOf(answers.release)])
        }
      }),
      map(release => ({ movie, release }))
    )
  }

  function grab(movie, release, context = {}) {
    log('ðŸŽŸï¸ ', `Grabbing ${chalk.inverse(release.title)} from ${chalk.gray(release.site)}`)
    logger.fetch(`ðŸŽŸï¸ Grabbing **${release.title}** from **_${release.site}_**`, { context, success: true, release })

    return of(null).pipe(
      mergeMap(() => of(sensorr.config.blackhole).pipe(
        mergeMap(blackhole => bindNodeCallback(fs.access)(blackhole, fs.constants.W_OK).pipe(
          map(err => !err),
          mergeMap(exist => exist ? of(null) : bindNodeCallback(fs.mkdir)(blackhole, { recursive: true })),
          mergeMap(err => err ? throwError(err) : of(null)),
        )),
      )),
      mergeMap(() => of(release.link).pipe(
        mergeMap(link => fetch(encodeURI(link))),
        mergeMap(res => res.buffer()),
        mergeMap(buffer => bindNodeCallback(fs.writeFile)(`${sensorr.config.blackhole}/${release.meta.generated}-${release.site}.torrent`, buffer).pipe(
          mergeMap(err => err ? throwError(err) : of(`${sensorr.config.blackhole}/${release.meta.generated}-${release.site}.torrent`)),
        )),
      )),
      mergeMap(file => of(null).pipe(
        mergeMap(() => db.movies.atomicUpsert({
          ...movie,
          time: Date.now(),
          state: 'archived',
        })),
        map(() => ({ movie, release, file })),
      )),
      delay(3000),
    )
  }

  async function stalk() {
    const tmdb = new TMDB({ key: config.tmdb, region: config.region })
    log('')

    return await new Promise(resolve =>
      from(db.stars.dump()).pipe(
        pluck('docs'),
        tap(stars => stars.filter(star => star.state === 'stalked').length ? '' : log('ðŸ§', `Oh. It seems you're not stalking anyone.`)),
        mergeMap(stars => zip(
          from(stars.filter(star => star.state === 'stalked')),
          interval(1000),
          (star, i) => star,
        )),
        mergeMap(star => from(tmdb.fetch(['person', star.id], { append_to_response: 'images,movie_credits' })).pipe(
          mergeMap(entity => from(db.stars.atomicUpsert(new Documents.Star(entity).normalize())).pipe(
            mapTo({ previous: star, current: new Documents.Star(entity).normalize() }),
          )),
          delay(2000),
        )),
      ).subscribe(
        ({ previous, current }) => log(
          'ðŸ“°',
          'Stalked',
          `star ${chalk.inverse(current.name)}${current.birthday ? chalk.gray(` (${current.birthday})`) : ''}`,
          'with',
          `${chalk.inverse(current.credits.length)}${current.credits.length > previous.credits.length ? ` (+${current.credits.length - previous.credits.length})` : ''} movie credits !`,
        ),
        (err) => log('ðŸš¨', err),
        () => {
          log('')
          resolve()
        },
      )
    )
  }

  async function sync() {
    log('')

    return await new Promise(resolve => {
      if (config.plex && config.plex.token) {
        const plex = new Plex(config.plex)
        const tmdb = new TMDB({ key: config.tmdb, region: config.region })

        log(`ðŸ“º `, `Looking for owned movies on ${chalk.inverse(plex.url)} Plex server ...`)

        from(plex.client.query('/library/sections')).pipe(
          mergeMap(payload => from(payload.MediaContainer.Directory.filter((directory) => directory.type === 'movie'))),
          mergeMap(section => plex.client.query(`/library/sections/${section.key}/all`)),
          tap(payload => log('ðŸŽžï¸ ', `Found ${chalk.bold(payload.MediaContainer.Metadata.length)} movies available on Plex server`)),
          mergeMap(payload => from(payload.MediaContainer.Metadata)),
          mergeMap(payload => from(plex.client.query(payload.key)).pipe(
            map(payload => payload.MediaContainer.Metadata.pop().guid),
            map(guid => guid.split('://').reduce(
              (acc, curr, index, arr) => ['com.plexapp.agents.imdb', 'com.plexapp.agents.themoviedb'].includes(arr[0]) ?
              { agent: arr[0], id: arr[1].split('?').shift() } :
              null
            )),
            filter(guid => guid),
            tap(guid => log('ðŸ”— ', `Handle ${chalk.bold(JSON.stringify(guid))} guid from Plex server`)),
            mergeMap(guid => of(guid).pipe(
              mergeMap(guid => db.movies.findOne().where({ 'com.plexapp.agents.imdb': 'imdb_id', 'com.plexapp.agents.themoviedb': 'id' }[guid.agent]).eq(guid.id).exec()),
              mergeMap(doc => doc ?
                of(doc.toJSON()).pipe(
                  tap(movie => movie.state === 'archived' && log('ðŸ“¼', `Sensorr movie ${chalk.inverse(movie.title)} already ${chalk.gray('archived')}`)),
                  filter(movie => movie.state !== 'archived'),
                  map(movie => ({ ...movie, time: Date.now(), state: 'archived' })),
                ) :
                of(guid).pipe(
                  tap(guid => log('ðŸ“­', `Missing ${chalk.inverse({ 'com.plexapp.agents.imdb': 'IMDB', 'com.plexapp.agents.themoviedb': 'TMDB' }[guid.agent])} movie ${chalk.gray(guid.id)}`)),
                  mergeMap(guid => ({
                    'com.plexapp.agents.themoviedb': of(guid.id),
                    'com.plexapp.agents.imdb': from(tmdb.fetch(['find', guid.id], { external_source: 'imdb_id' })).pipe(map(payload => payload.movie_results.pop().id)),
                  }[guid.agent])),
                  mergeMap(id => tmdb.fetch(['movie', id], { append_to_response: 'alternative_titles,release_dates' })),
                  map(entity => new Documents.Movie({ ...entity, state: 'archived' }, config.region).normalize()),
                )
              ),
              mergeMap(movie => from(db.movies.atomicUpsert(movie)).pipe(mapTo(movie))),
            )),
            delay(2000),
          ), null, 1),
        ).subscribe(
          (movie) => log('ðŸ“¼', `Sensorr movie ${chalk.inverse(movie.title)} is available on Plex server, will now be ${chalk.gray('archived')}`),
          (err) => {
            log('ðŸš¨', err)
            resolve()
          },
          () => {
            log('')
            resolve()
          },
        )
      } else {
        log('ðŸš¨', 'Missing token, are you sure Plex server is connected with your Sensorr instance ?')
        log('')
        resolve()
      }
    })
  }
}
